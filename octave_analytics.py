import numpy as np
from scipy.cluster.hierarchy import linkage
from scipy.cluster.hierarchy import fcluster
from scipy.cluster.hierarchy import dendrogram
import scipy.io as sio
import matplotlib.pyplot as plt

def clustering(dataset, problem_numbers, show_dendogram=False):
	'''
	performs clustering on the given dataset
	converted from clustering.m (octave code)
	input:
		- dataset: Features X Problems matrix (M,N)
		- problem_numbers: vector of problem ids (Nx1)
	output:
		- Z_link_label:
			- Column 1: new cluster number (starting at N+1)
			- Column 2: problem_id (airtable field value), or 0 if already generated cluster
			- Column 3: problem_id (airtable field value), or 0 if already generated cluster
			- Column 4: data/cluster num generated by linkage function
			- Column 5: data/cluster num generated by linkage function
			- Column 6: distance based on metric on method provided
			- Column 7: number of datum in this cluster
		- clusters:
			- List of cluster of problem_ids that satisfies the error provided
	'''
	# Add problem ids as first row (transpose to 1xN)
	M,N = dataset.shape
	datanum = np.zeros((M+1,N))
	datanum[0,:] = problem_numbers
	datanum[1:,:] = dataset
	datanum = datanum.T

	# Randomize the problem order
	# random.shuffle permutes the rows, so transpose first to shuffle columns
	# Now in Problems x Features
	np.random.shuffle(datanum)
	shuffled_data = datanum[:,1:]
	shuffled_problem_order = datanum[:,0]
	satisfied = False
	Z = None

	while not satisfied:
		err = input('Please input a maximum distance between 0 and 1\n')
		err = float(err)

		# Z = linkage(data, method, metric)
		# data is size (N_problems x M_features)
		# Z is size (N_problems-1, 4)
		# Columns 1 and 2 are cluster indices that are linked
		# Column 3 is linkage distance
		# Cluster 4 is number of problems in this cluster
		Z = linkage(shuffled_data, 'average', 'jaccard')
		count_under_distance = sum(z[2] < err for z in Z)
		choice = input('There are {} problems under that distance. If you want to continue, enter "c". If you want to adjust distance, enter "a"\n'.format(count_under_distance))
		if choice == 'c':
			satisfied = True
		elif choice == 'a':
			satisfied = False
		# Default to false
		else:
			satisfied = False

	link_labels = np.zeros((N-1, 3))

	if show_dendogram:
		plt.figure()
		dn = dendrogram(Z)
		plt.show()

	for i in range(Z.shape[0]):
		# First column is the new cluster number, defined as NProblems + 1
		link_labels[i,0] = shuffled_data.shape[0] + i
		# label problem numbers in first column of y
		# if adding individual problem to cluster, use problem number from airtable
		# if adding a previously generated cluster, use 0
		if Z[i,0] <= N:
			link_labels[i,1] = shuffled_problem_order[int(Z[i,0])-1]
		else:
			link_labels[i,1] = 0
		# label problem numbers in second column of y
		# if adding individual problem to cluster, use problem number
		# if adding a previously generated cluster, use 0
		if Z[i,1] <= N:
			link_labels[i,2] = shuffled_problem_order[int(Z[i,1])-1]
		else:
			link_labels[i,2] = 0

	# Z_link_label is size (N_problems-1, 6)
	# Columns 1 is cluster_number
	# Column 2 is problem number or 0, depending on if original problem or previous cluster
	# Column 3 is problem number or 0, depending on if original problem or previous cluster
	# Column 4 is problem/cluster number in this cluster
	# Column 5 is problem/cluster number in this cluster
	# Column 6 is distance between joined problems/clusters
	# Column 7 is total number of problems in cluster
	Z_link_label = np.zeros((N-1,7))
	Z_link_label[:,:3] = link_labels
	Z_link_label[:,3:] = Z
	zlklb = []

	# Choose error (distance) and take all clustering within that distance
	# err defined at start as user input
	for i in range(N-1):
		if Z_link_label[i,5] <= err:
			zlklb.append(tuple(Z_link_label[i,:]))
	
	# Now group clusters (condense and make readable)
	# If previously generated cluster, find cluster label
	cref = []
	for i in range(len(zlklb)):
		tmp_list = [0,0]
		if zlklb[i][1] == 0:
			# Containing cluster
			tmp_list[0] = zlklb[i][3] - N
		if zlklb[i][2] == 0:
			# Containing cluster
			tmp_list[1] = zlklb[i][4] - N

		cref.append(tuple(tmp_list))

	C = []
	for i in range(len(cref)):
		if cref[i][0] == 0 and cref[i][1] == 0:
			# original problem numbers
			C.append(list(zlklb[i][1:3]))
		elif cref[i][0] == 0 and cref[i][1] > 0:
			# original prolbem number and new cluster number
			C.append([zlklb[i][1]] + list(C[int(cref[i][1])]))
			C[int(cref[i][1])] = 0
		elif cref[i][0] > 0 and cref[i][1] == 0:
			# new cluster number and original problem number
			C.append(list(C[int(cref[i][0])]) + [zlklb[i][2]])
			C[int(cref[i][0])] = 0
		elif cref[i][0] > 0 and cref[i][1] > 0:
			C.append(list(C[int(cref[i][0])]) + list(C[int(cref[i][1])]))
			C[int(cref[i][0])] = 0
			C[int(cref[i][1])] = 0

	# Any problems that were not clustered yet, make each its own cluster
	for i in range(len(cref),Z_link_label.shape[0]):
		if Z_link_label[i][1] > 0:
			C.append(Z_link_label[i][1])
		if Z_link_label[i][2] > 0:
			C.append(Z_link_label[i][2])

	# Get rid of empty cells to condense and clearly view clusters
	clusters = []
	for i in range(len(C)):
		if C[i] == 0:
			continue
		else:
			clusters.append(C[i])

	return Z_link_label, clusters


# For testing purposes
if __name__ == '__main__':
	'''
	Running this from main is for the purpose of quickly seeing how the function works,
	or for testing/modifying.
	As of now, running from main expects the following files to be in the 
	same directory as where the script is being run:
		- jtbddata.mat
		- processesdata.mat
		- problem_numbers.mat 
		- alldata.mat

	Comment out/modify as needed
	'''
	jtbdmatrix = sio.loadmat('jtbddata.mat')
	processmatrix = sio.loadmat('processesdata.mat')
	problemnumbers = sio.loadmat('problem_numbers.mat')
	alldata = sio.loadmat('alldata.mat')
	c = input('Would you like to view a dendogram of all the data? [y/n]\n')
	choice = False
	if c == 'y':
		choice = True
	dataset = None
	c = input('Which dataset would you like to use? (j)tbd, (p)rocesses, or (b)oth [j/p/b]?\n')
	if c == 'j':
		dataset = jtbd['jtbddata']
	if c == 'p':
		dataset = processmatrix['processesdata']
	if c == 'b':
		dataset = alldata['alldata']

	Zlklb, clusters = clustering(dataset, problemnumbers['problemnumbers'], show_dendogram=choice)
	strclusters = [str(c) for c in clusters]
	print('Here are the airtable problem_ids clustered by similarity {}'.format('\n'.join(strclusters)))




